{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(exploratory-data-analysis)=\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This chapter will show you how to use visualisation and transformation to explore your data in a systematic way, a task that data scientists call exploratory data analysis, or EDA for short. EDA is an iterative cycle; you:\n",
    "\n",
    "1.  Generate questions about your data.\n",
    "\n",
    "2.  Search for answers by visualising, transforming, and modelling your data.\n",
    "\n",
    "3.  Use what you learn to refine your questions and/or generate new questions.\n",
    "\n",
    "EDA is not a formal process with a strict set of rules and, during the initial phases of EDA, you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive areas that you'll eventually write up and communicate to others. As you explore your data, you should remember that there are some pitfalls: you should always think about how the data were collected, what might be missing, whether there are quality problems, and be really strict about the differences between correlation and causation (this is a huge topic in itself!).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For doing EDA, we'll use the **pandas**, **skimpy**, and **pandas-profiling** packages. You are likely to already have **pandas** installed. To install the other two packages, open up a terminal in Visual Studio Code and run `pip install skimpy` and `pip install pandas-profiling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a55374",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\n",
    "    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n",
    ")\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddb863",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "> \"There are no routine statistical questions, only questionable statistical routines.\" --- Sir David Cox\n",
    "> \"Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.\" --- John Tukey\n",
    "\n",
    "Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\n",
    "\n",
    "EDA is fundamentally a creative process. And like most creative processes, the key to asking *quality* questions is to generate a large *quantity* of questions. It is difficult to ask revealing questions at the start of your analysis because you do not know what insights are contained in your dataset. On the other hand, each new question that you ask will expose you to a new aspect of your data and increase your chance of making a discovery. You can quickly drill down into the most interesting parts of your data---and develop a set of thought-provoking questions---if you follow up each question with a new question based on what you find.\n",
    "\n",
    "There is no rule about which questions you should ask to guide your research. However, two types of questions will always be useful for making discoveries within your data. You can loosely word these questions as:\n",
    "\n",
    "1.  What type of variation occurs within my variables?\n",
    "\n",
    "2.  What type of covariation occurs between my variables?\n",
    "\n",
    "The rest of this chapter will look at these two questions. We'll explain what variation and covariation are, and We'll show you several ways to answer each question. To make the discussion easier, let's define some terms:\n",
    "\n",
    "-   A **variable** is a quantity, quality, or property that you can measure.\n",
    "\n",
    "-   A **value** is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.\n",
    "\n",
    "-   An **observation** is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We'll sometimes refer to an observation as a data point.\n",
    "\n",
    "-   **Tabular data** is a set of values, each associated with a variable and an observation. Tabular data is *tidy* if each value is placed in its own \"cell\", each variable in its own column, and each observation in its own row.\n",
    "\n",
    "So far, all of the data that you've seen has been tidy. In real-life, most data isn't tidy, so we'll come back to how to clean untidy data later in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adeff41",
   "metadata": {},
   "source": [
    "[TODO]\n",
    "[placeholder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f4de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diamonds = pd.read_csv(\n",
    "    \"https://github.com/mwaskom/seaborn-data/raw/master/diamonds.csv\"\n",
    ")\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14158b48",
   "metadata": {},
   "source": [
    "## **pandas** built-in tools for EDA\n",
    "\n",
    "**pandas** has some great options for built-in EDA; in fact we've already seen one of them, `df.info()` which, as well as reporting datatypes and memory usage, also tells us how many observations in each column are 'truthy' rather than 'falsy', ie how many have non-null values.\n",
    "\n",
    "### Exploratory tables and descriptive statistics\n",
    "\n",
    "A small step beyond `.info()` to get tables is to use `.describe()` which, if you have mixed datatypes that include floats, will report some basic summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13079065",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57dbb7",
   "metadata": {},
   "source": [
    "Although helpful, that sure is hard to read! We can improve this by using the `round()` method too:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4144440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = diamonds.describe().round(1)\n",
    "sum_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063b8f5",
   "metadata": {},
   "source": [
    "Published summary statistics tables often list one variable per row, and if your dataframe has many variables, `describe()` can quickly get too wide to read easily. You can transpose it using the `T` property (or the `transpose()` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = sum_table.T\n",
    "sum_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67104d3",
   "metadata": {},
   "source": [
    "Of course, the stats provided in this pre-built table are not very customised. So what do we do to get the table that we actually want? Well, the answer is to draw on the contents of the previous data chapters, particularly the introduction to data analysis. Groupbys, merges, aggregations: use all of them to produce the EDA table that you want.\n",
    "\n",
    "If you're exploring data, you might also want to be able to read everything clearly and see any deviations from what you'd expect quickly. **pandas** has some built-in functionality that styles dataframes to help you. These styles persist when you export the dataframe to, say, Excel, too.\n",
    "\n",
    "Here's an example that highlights some ways of styling dataframes, making use of several features such as: unstacking into a wider format (`unstack`), changing the units (`lambda` function; note that `1e3` is shorthand for `1000` on computers), fill NaNs with unobtrusive strings (`.fillna('-')`), removing numbers after the decimal place (`.style.format(precision=0)`), and adding a caption (`.style.set_caption`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    diamonds.groupby([\"cut\", \"color\"])\n",
    "    .mean()[\"price\"]\n",
    "    .unstack()\n",
    "    .apply(lambda x: x / 1e3)\n",
    "    .fillna(\"-\")\n",
    "    .style.format(precision=2)\n",
    "    .set_caption(\"Sale price (thousands)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e0fc1",
   "metadata": {},
   "source": [
    "Although a neater one than we've seen, this is still a drab table of numbers. The eye is not immediately drawn to it!\n",
    "\n",
    "To remedy that, let's take a look at another styling technique: the use of colour. Let's say we wanted to make a table that showed a cross-tabulation between cut and color; that is the counts of objects appearing in both of these fields according to the categories.\n",
    "\n",
    "To perform a cross-tabulation, we'll use the built-in `pd.crosstab` but we'll ask that the values that appear in the table (counts) be lit up with a heatmap using `style.background_gradient` too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e65189",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"]).style.background_gradient(cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6aa71",
   "metadata": {},
   "source": [
    "By default, `background_gradient` highlights each number relative to the others in its column; you can highlight by row using `axis=1` or relative to all table values using `axis=0`. And of course `plasma` is just one of [many available colormaps](https://matplotlib.org/stable/tutorials/colors/colormaps.html)!\n",
    "\n",
    "```{admonition} Exercise\n",
    "Do a new cross-tabulation using a different colourmap.\n",
    "```\n",
    "\n",
    "Here are a couple of other styling tips for dataframes.\n",
    "\n",
    "First, use bars to show ordering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"])\n",
    "    .style.format(precision=0)\n",
    "    .bar(color=\"#d65f5f\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d4795",
   "metadata": {},
   "source": [
    "Use `.hightlight_max`, and similar commands, to show important entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"]).style.highlight_max().format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63075da4",
   "metadata": {},
   "source": [
    "You can find a full set of styling commands [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#Styling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6d225",
   "metadata": {},
   "source": [
    "### Exploratory Plotting with **pandas**\n",
    "\n",
    "**pandas** has some built-in plotting options to help you look at data quickly. These can be accessed via `.plot.*` or `.plot()`, depending on the context. Let's make a quick `.plot()` using a dataset on taxis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = pd.read_csv(\"https://github.com/mwaskom/seaborn-data/raw/master/taxis.csv\")\n",
    "# turn the pickup time column into a datetime\n",
    "# taxis[\"pickup\"] = pd.to_datetime(taxis[\"pickup\"])\n",
    "# set some other columns types\n",
    "taxis = taxis.astype(\n",
    "    {\n",
    "        \"dropoff\": \"datetime64\",\n",
    "        \"pickup\": \"datetime64\",\n",
    "        \"color\": \"category\",\n",
    "        \"payment\": \"category\",\n",
    "        \"pickup_zone\": \"string\",\n",
    "        \"dropoff_zone\": \"string\",\n",
    "        \"pickup_borough\": \"category\",\n",
    "        \"dropoff_borough\": \"category\",\n",
    "    }\n",
    ")\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee971c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    taxis.set_index(\"pickup\")\n",
    "    .groupby(pd.Grouper(freq=\"D\"))[\"total\"]\n",
    "    .mean()\n",
    "    .plot(\n",
    "        title=\"Mean taxi fares\",\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"Fare (USD)\",\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f990",
   "metadata": {},
   "source": [
    "Again, if you can get the data in the right shape, you can plot it. The same function works with multiple lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e86185",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    taxis.set_index(\"pickup\")\n",
    "    .groupby(pd.Grouper(freq=\"D\"))[[\"fare\", \"tip\", \"tolls\"]]\n",
    "    .mean()\n",
    "    .plot(\n",
    "        style=[\"-\", \":\", \"-.\"],\n",
    "        title=\"Components of taxi fares\",\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"USD\",\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc227b81",
   "metadata": {},
   "source": [
    "Now let's see some of the other quick `.plot.*` options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4278ac",
   "metadata": {},
   "source": [
    "A bar chart (use `barh` for horizontal orientation; `rot` sets rotation of labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ceca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.value_counts(\"payment\").sort_index().plot.bar(title=\"Counts\", rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1cc2",
   "metadata": {},
   "source": [
    "This next one, uses `.plot.hist` to create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis[\"tip\"].plot.hist(bins=30, title=\"Tip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15bfa7",
   "metadata": {},
   "source": [
    "Boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b735d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "(taxis[[\"fare\", \"tolls\", \"tip\"]].plot.box());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017bef",
   "metadata": {},
   "source": [
    "Scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.plot.scatter(x=\"fare\", y=\"tip\", alpha=0.7, ylim=(0, None));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766d2c4",
   "metadata": {},
   "source": [
    "## Other tools for EDA\n",
    "\n",
    "Between **pandas** and visualisation packages, you have a lot of what you need for EDA. But there are some tools just dedicated to making EDA easier that it's worth knowing about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ec70a",
   "metadata": {},
   "source": [
    "### **skimpy** for summary statistics\n",
    "\n",
    "The **skimpy** package is a light weight tool that provides summary statistics about variables in data frames in the console (rather than in a big HTML report, which is what the other EDA packages in the rest of this chapter too). Sometimes running `.summary()` on a data frame isn't enough, and **skimpy** fills this gap. It also comes with the `clean_columns` function for cleaning column names that we saw in an earlier chapter. To install **skimpy**, run `pip install skimpy` in the terminal.\n",
    "\n",
    "Let's see **skimpy** in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32796b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "\n",
    "skim(taxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fc099",
   "metadata": {},
   "source": [
    "### The **pandas-profiling** package\n",
    "\n",
    "The EDA we did using the built-in **pandas** functions was a bit limited and user-input heavy. The [**pandas-profiling**](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/) library aims to automate the legwork of EDA for you. It generates 'profile' reports from a pandas DataFrame. For each column, many statistics are computed and then relayed in an interactive HTML report. To install it, run `pip install pandas-profiling` in the terminal.\n",
    "\n",
    "Let's generate a report on our dataset. If you are using a large dataset, you may wish to employ the`minimal=True` setting that cuts out a lot of computationally expensive extras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39739f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "profile = ProfileReport(taxis, minimal=True, title=\"Profiling Report: Taxis Dataset\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2494069",
   "metadata": {},
   "source": [
    "This is a full on report about everything in our dataset! We can see, for instance, that we have 14 variables and what kind each of them are.\n",
    "\n",
    "The alerts page shows where **pandas-profiling** really shines. It flags *potential* issues with the data that should be taken into account in any subsequent analysis. For example, although not relevant here, the report will say if there are very unbalanced classes in a low cardinality categorical variable.\n",
    "\n",
    "Another good package for automated EDA is [dataprep](https://dataprep.ai/)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d7534ecd9fbc7d385378f8400cf4d6cb9c6175408a574f1c99c5269f08771cc"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
