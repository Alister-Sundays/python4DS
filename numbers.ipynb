{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(numbers)=\n",
    "# Numbers\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this chapter, you'll learn useful tools for creating and manipulating numeric vectors. We'll start by going into a little more detail of `.count()` before diving into various numeric transformations. You'll then learn about more general transformations that can be applied to other types of column, but are often used with numeric column. Then you'll learn about a few more useful summaries.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This chapter mostly uses functions from **pandas**, which you are likely to already have installed bu you can install using `pip install pandas` in the terminal. We'll use real examples from nycflights13, as well as toy examples made with fake data.\n",
    "\n",
    "Let's first load up the NYC flights data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a55374",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\n",
    "    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n",
    ")\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/flights/flights.csv\"\n",
    "flights = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1fd34",
   "metadata": {},
   "source": [
    "### Counts\n",
    "\n",
    "It's surprising how much data science you can do with just counts and a little basic arithmetic, so **pandas** strives to make counting as easy as possible with `.count()` and `.value_counts()`. The former just provides a straight count of all the non NA items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[\"dest\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8140f",
   "metadata": {},
   "source": [
    "The latter provides a count broken down by type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[\"dest\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb110f3",
   "metadata": {},
   "source": [
    "This is automatically sorted in order of the most common category. You can perform the same computation \"by hand\" with `group_by()`, `agg()` and then using the count function. This is useful because it allows you to compute other summaries at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    flights.groupby([\"dest\"])\n",
    "    .agg(\n",
    "        mean_delay=(\"dep_delay\", \"mean\"),\n",
    "        count_flights=(\"dest\", \"count\"),\n",
    "    )\n",
    "    .sort_values(by=\"count_flights\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b23fa",
   "metadata": {},
   "source": [
    "Note that a weighted count is just a sum. For example you could \"count\" the number of miles each plane flew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061decae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(flights.groupby(\"tailnum\").agg(miles=(\"distance\", \"sum\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b489765",
   "metadata": {},
   "source": [
    "You can count missing values by combining `sum()` and `isnull()`. In the flights dataset this represents flights that are cancelled. Note that because there isn't a simple string name for applying `.isnull` followed by `.sum` (unlike just running `sum`, which would be given by the string \"sum\"), we need to use a lambda function in the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "(flights.groupby(\"dest\").agg(n_cancelled=(\"dep_time\", lambda x: x.isnull().sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587dbe2",
   "metadata": {},
   "source": [
    "## Numeric Transformations\n",
    "\n",
    "Transformation functions have an output is the same length as the input. The vast majority of transformation functions are either built into Python or come with the numerical package **numpy**. It's impractical to list all the possible numerical transformations so this section will show the most useful ones.\n",
    "\n",
    "Basic number arithmatic is achieved by `+` (addition), `-` (subtraction), `*` (multiplication), `/` (division), `**` (powers), `%` (modulo), and `@` (tensor product). Most of these functions don't need a huge amount of explanation because you'll be familiar with them already (and you can look up the others when you do need them).\n",
    "\n",
    "When you have two numeric columns of equal length and you add or subtract them, it's pretty obvious what's going to happen. But we do need to talk about what happens when there is a variable involved that is *not* as long as the column. This is important for operations like `flights.assign(air_time = air_time / 60)` because there are 336,776 numbers on the left of `/` but only one on the right. In this case, **pandas** will understand that you'd like to divide *all* values of air time by 60. This is sometimes called 'broadcasting'. Below is a digram that tries to explain what's going on:\n",
    "\n",
    "![](https://numpy.org/doc/stable/_images/broadcasting_1.png)\n",
    "\n",
    "You can find out much more about [broadcasting on the **numpy** documentation](https://numpy.org/doc/stable/user/basics.broadcasting.html). **pandas** is built on top of **numpy** and inherits some of its functionality.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb10890",
   "metadata": {},
   "source": [
    "When operating on two columns, **pandas** compares their shapes element-wise. Two columns are compatible when they are equal, or one of them is a scalar. If these conditions are not met, you will get an error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e62aed",
   "metadata": {},
   "source": [
    "### Minimum and Maximum\n",
    "\n",
    "The arithmetic functions do what you'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[\"distance\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24faa5",
   "metadata": {},
   "source": [
    "Sometimes, you'd like to look at the maximum or minimum value across rows *or* columns. As often is the case with **pandas**, you can specify rows or columns to apply functions to by passing `axis=0` (index) or `axis=1` (columns) to that function. The axis designation can be confusing: remember that you are asking which dimension you wish to aggregate over, leaving you with the other dimension. So if we wish to find the minimum in each row, we aggregate / collapse columns, so we need to pass `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96285702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\": [1, 5, 7], \"y\": [3, 2, pd.NA]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aabe248",
   "metadata": {},
   "source": [
    "Now let's find the min by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b455a",
   "metadata": {},
   "source": [
    "### Modular arithmetic\n",
    "\n",
    "Modular arithmetic is the technical name for the type of math you do on whole numbers, i.e. division that yields a whole number and a remainder. In Python, `//` does integer division and `%` computes the remainder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in range(1, 11)])\n",
    "print(\"divided by 3 gives\")\n",
    "print(\"remainder:\")\n",
    "print([x % 3 for x in range(1, 11)])\n",
    "print(\"divisions:\")\n",
    "print([x // 3 for x in range(1, 11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a7811",
   "metadata": {},
   "source": [
    "Modular arithmetic is handy for the flights dataset, because we can use it to unpack the `sched_dep_time` variable into and `hour` and `minute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be57e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.assign(\n",
    "    hour=lambda x: x[\"sched_dep_time\"] // 100,\n",
    "    minute=lambda x: x[\"sched_dep_time\"] % 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfcc59",
   "metadata": {},
   "source": [
    "We can combine that with the `mean(is.na(x))` trick from @sec-logical-summaries to see how the proportion of cancelled flights varies over the course of the day. [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfc9c7",
   "metadata": {},
   "source": [
    "### Logarithms\n",
    "\n",
    "Logarithms are an incredibly useful transformation for dealing with data that ranges across multiple orders of magnitude.\n",
    "They also convert exponential growth to linear growth. For example, take compounding interest --- the amount of money you have at `year + 1` is the amount of money you had at `year` multiplied by the interest rate. That gives a formula like `money = starting * interest ** year`:\n",
    "\n",
    "```{r}\n",
    "starting <- 100\n",
    "interest <- 1.05\n",
    "money <- tibble(\n",
    "  year = 2000 + 1:50,\n",
    "  money = starting * interest^(1:50)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "starting = 100\n",
    "interest = 1.05\n",
    "money = pd.DataFrame(\n",
    "    {\"year\": 2000 + np.arange(1, 51), \"money\": starting * interest ** np.arange(1, 51)}\n",
    ")\n",
    "money.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4afd0",
   "metadata": {},
   "source": [
    "If you plot this data, you'll get an exponential curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "money.plot(x=\"year\", y=\"money\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a0f24",
   "metadata": {},
   "source": [
    "Log transforming the y-axis gives a straight line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "money.plot(x=\"year\", y=\"money\", logy=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9a267",
   "metadata": {},
   "source": [
    "This a straight line because `log(money) = log(starting) + n * log(interest)` matches the pattern for a line, `y = m * x + b`. This is a useful pattern: if you see a (roughly) straight line after log-transforming the y-axis, you know that there's underlying exponential growth.\n",
    "\n",
    "If you're log-transforming your data you have a choice of a lot of logarithms provided by **numpy** but there are three ones you'll want to commonly use: assuming you've imported it using `import numpy as np`, you have `np.log()` (the natural log, base e), `np.log2()` (base 2), and `np.log10()` (base 10).\n",
    "\n",
    "The inverse of `log()` is `np.exp()`; to compute the inverse of `np.log2()` or `np.log10()` you'll need to use `2**` or `10**`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d7534ecd9fbc7d385378f8400cf4d6cb9c6175408a574f1c99c5269f08771cc"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
