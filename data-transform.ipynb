{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(data-transform)=\n",
    "# Data Transformation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Visualization is an important tool for generating insight, but it's rare that you get the data in exactly the right form you need to make the graph you want.\n",
    "Often you'll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with.\n",
    "You'll learn how to do all that (and more!) in this chapter, which will introduce you to data transformation using the **polars** package and a dataset on flights that departed New York City in 2013.\n",
    "\n",
    "The goal of this chapter is to give you an overview of all the key tools for transforming a data frame.\n",
    "We'll start with functions that operate on rows and then columns of a data frame, then circle back to talk more about the pipe, an important tool that you use to combine verbs.\n",
    "We will then introduce the ability to work with groups.\n",
    "We will end the chapter with a case study that showcases these functions in action and we'll come back to the functions in more detail in later chapters, as we start to dig into specific types of data (e.g., numbers, strings, dates).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "In this chapter we'll focus on the **polars** package, which is for processing data. It's not actually the most popular package for data analysis in Python: that crown belongs to **pandas**, but polars has a few advantages including its more consistent syntax (which makes it easier to learn!) and the fact that it's a LOT faster in some situations.\n",
    "\n",
    "You'll need to install **polars** (run `pip install polars` in your terminal if you haven't already)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cc0a4",
   "metadata": {},
   "source": [
    "If this command fails, you don't have **polars** installed. Furthermore, if you wish to check which version of **polars** you're using, it's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afedbb",
   "metadata": {},
   "source": [
    "### nycflights13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e5b82",
   "metadata": {},
   "source": [
    "Let's get some data! Most of the time, data will need to be loaded from a file or the internet. These data are no different, but one of the amazing things about **polars** is how many different types of data it can load, including from files on the internet. The data are \n",
    "Let's download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff283e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/flights/flights.csv\"\n",
    "flights = pl.read_csv(url, null_values=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907635c",
   "metadata": {},
   "source": [
    "If the above code worked, then you've downloaded the data in CSV format and put it in a data frame. You may have noticed we used a keyword argument `null_values`. The reason is that this dataset has some fields set to \"NA\", and we need to tell **polars** to treat these as null (ie missing data) rather than as anything else. Such issues are common with real world datasets!\n",
    "\n",
    "This dataset contains all flights that departed from New York City in 2013. The data originally come from the US [Bureau of Transportation Statistics](http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0).\n",
    "\n",
    "Let's look at the first few rows using the `.head()` function that works on all **polars** data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f99d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100189b8",
   "metadata": {},
   "source": [
    "You might have noticed the short abbreviations that appear in the `Dtypes` column. These tell you the type of the values in their respective columns: `int64` is short for integer (eg whole numbers) and `float64` is short for double-precision floating point number (these are real numbers). `object` is a bit of a catch all category for any data type that **pandas** is not really confident about inferring. Although not found here, other data types include `string` for text and `datetime` for combinations of a date and time.\n",
    "\n",
    "The table below gives some of the most common data types you are likely to encounter.\n",
    "\n",
    "|  **Name of data type**  |    **Type of data**   |\n",
    "|:----------:|:-------------:|\n",
    "|   float64  |  real numbers |\n",
    "|  category  |   categories  |\n",
    "| datetime |   date and time  |\n",
    "|    int64   |    integers   |\n",
    "|    boolean    | True or False |\n",
    "|   string   |      text     |\n",
    "|   Null   |      Invalid or missing value     |\n",
    "\n",
    "The different column data types are important because the operations you can perform on a column depend so much on its \"type\"; for example, you can remove all punctuation from strings while you can multiply ints and floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6490c4b",
   "metadata": {},
   "source": [
    "We need to do one more thing before our data are ready to use. We would like to work with the `\"time_hour\"` variable in the form of a datetime; fortunately, **polars** makes it easy to perform that conversion on that specific column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17186e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights.with_columns(pl.col(\"time_hour\").str.to_datetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec665677",
   "metadata": {},
   "source": [
    "### **polars** basics\n",
    "\n",
    "The two core components of **polars** are *contexts* and *expressions*. We're going to start with contexts. A context, as implied by the name, refers to the context in which an expression needs to be evaluated. There are three main contexts, shown here operating on an arbitrary dataframe `df`.\n",
    "\n",
    "1. Selection, for example of columns: `df.select([..])`, `df.with_columns([..])`\n",
    "2. Filtering, for example of rows: `df.filter()`\n",
    "3. Groupby / Aggregation: `df.groupby(..).agg([..])`\n",
    "\n",
    "Because each does one thing well, solving complex problems will usually require combining these. This is usually done by *chaining* them together, so you get lines of code like: `df.with_columns([]).filter().agg()`, where the brackets would be filled by the names of columns and variables. The easiest way to think about this is that each time you see a full stop between code, you're saying \"then do this\". The beauty of this approach is that it makes it easy to read, and to write: even in this very abstract expression you can guess that we're taking a dataframe *then* only using some columns, *then* we're filtering them by a condition, *then* we're aggregating them somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd470bbf",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "The most important method that operates on rows of a dataset is .`filter()`, which changes which rows are present without changing their order.\n",
    "This only affects the rows, while the columns are left unchanged. For example, we could find all flights that departed more than 120 minutes (two hours) late."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d7534ecd9fbc7d385378f8400cf4d6cb9c6175408a574f1c99c5269f08771cc"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
