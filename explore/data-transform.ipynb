{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(data-transform)=\n",
    "# Data Transformation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "It's very rare that data arrive in exactly the right form you need. Often, you'll need to create some new variables or summaries, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with.\n",
    "\n",
    "You'll learn how to do all that (and more!) in this chapter, which will introduce you to data transformation using the **pandas** package and a new dataset on flights that departed New York City in 2013.\n",
    "\n",
    "The goal of this chapter is to give you an overview of all the key tools for transforming a data frame, a special kind of object that holds tabular data.\n",
    "\n",
    "We'll come back these functions in more detail in later chapters, as we start to dig into specific types of data (e.g. numbers, strings, dates).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "In this chapter we'll focus on the **pandas** package, one of the most widely used tools for data science. You'll need to ensure you have **pandas** installed. To do this, you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cc0a4",
   "metadata": {},
   "source": [
    "If this command fails, you don't have **pandas** installed. Open up the terminal in Visual Studio Code (Terminal -> New Terminal) and type in `conda install pandas`.\n",
    "\n",
    "Furthemore, if you wish to check which version of **pandas** you're using, it's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e5b82",
   "metadata": {},
   "source": [
    "You'll also need the data. Most of the time, data will need to be loaded from a file or the internet. These data are no different, but one of the amazing things about **pandas** is how many different types of data it can load, including from files on the internet.\n",
    "\n",
    "The data is around 50MB in size so you will need a good internet connection or a little patience for it to download.\n",
    "\n",
    "Let's download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff283e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/flights/flights.csv\"\n",
    "flights = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907635c",
   "metadata": {},
   "source": [
    "If the above code worked, then you've downloaded the data in CSV format and put it in a data frame. Let's look at the first few rows using the `.head()` function that works on all **pandas** data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f99d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aada55",
   "metadata": {},
   "source": [
    "To get more general information on the columns, the data types (`dtypes`) of the columns, and the size of the dataset, use `.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dea97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100189b8",
   "metadata": {},
   "source": [
    "You might have noticed the short abbreviations that appear in the `Dtypes` column. These tell you the type of the values in their respective columns: `int64` is short for integer (eg whole numbers) and `float64` is short for double-precision floating point number (these are real numbers). `object` is a bit of a catch all category for any data type that **pandas** is not really confident about inferring. Although not found here, other data types include `string` for text and `datetime` for combinations of a date and time.\n",
    "\n",
    "The different column data types are important because the operations you can perform on a column depend so much on its \"type\"; for example, you can remove all punctuation from strings while you can multiply ints and floats.\n",
    "\n",
    "We would like to work with the `\"time_hour\"` variable in the form of a datetime; fortunately, **pandas** makes it easy to perform that conversion on that specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[\"time_hour\"] = pd.to_datetime(flights[\"time_hour\"], format = \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc43cee",
   "metadata": {},
   "source": [
    "## **pandas** basics\n",
    "\n",
    "**pandas** is a really comprehensive package, and this book will barely scratch the surface of what it can do. But it's built around a few simple ideas that, once they've clicked, make life a lot easier.\n",
    "\n",
    "Letâ€™s start with the absolute basics. The most basic pandas object is a dataframe. A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, categorical data, even lists) in columns. It is made up of rows and columns (with each row-column cell containing a value), plus two bits of contextual information: the index (which carries information about each row) and the column names (which carry information about each column).\n",
    "\n",
    "![](https://pandas.pydata.org/docs/_images/01_table_dataframe.svg)\n",
    "\n",
    "Perhaps the most important notion to have about **pandas** data frames is that they are built around an index that sits on the left-hand side of the data frame. Every time you perform an operation on a data frame, you need to think about how it might or might not affect the index; or, put another way, whether you want to modify the index.\n",
    "\n",
    "Let's see a simple example of this with a made-up data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"col0\": [0, 0, 0, 0],\n",
    "        \"col1\": [0, 0, 0, 0],\n",
    "        \"col2\": [0, 0, 0, 0],\n",
    "        \"col3\": [\"a\", \"b\", \"b\", \"a\"],\n",
    "        \"col4\": [\"alpha\", \"gamma\", \"gamma\", \"gamma\"],\n",
    "    },\n",
    "    index=[\"row\" + str(i) for i in range(4)],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ba56e",
   "metadata": {},
   "source": [
    "You can see there are 5 columns (named `\"col0\"` to `\"col4\"`) and that the index consists of four entries named `\"row0\"` to `\"row3\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f325661",
   "metadata": {},
   "source": [
    "A second key point you should know is that the operations on a **pandas** data frame can be chained together. We need not perform one assignment per line of code; we can actually do multiple assignments in a single command.\n",
    "\n",
    "Let's see an example of this. We're going to string together four operations:\n",
    "\n",
    "1. we will use `query` to find only the rows where the destination `\"dest\"` column has the value `\"IAH\"`. This doesn't change the index, it only removes irrelevant rows. In effect, this step removes rows we're not interested in.\n",
    "2. we will use `groupby` to group rows by the year, month, and day (we pass a list of columns to the `groupby` function). This step changes the index; the new index will have three columns in that track the year, month, and day. In effect, this step changes the index.\n",
    "3. we will choose which columns we wish to keep after the groupby operation by passing a list of them to a set of square brackets (the double brackets are because it's a list within a dataframe). Here we just want one column, `\"arr_delay\"`. This doesn't affect the index. In effect, this step removes columns we're not interested in.\n",
    "4. finally, we must specify what groupby operation we wish to apply; when aggregating the information in multiple rows down to one row, we need to say how that information should be aggregated. In this case, we'll use the mean. In effect, this step applies a statistic to the variable(s) we selected earlier, across the groups we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb114649",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    flights.query(\"dest == 'IAH'\")\n",
    "           .groupby([\"year\", \"month\", \"day\"])\n",
    "           [[\"arr_delay\"]]\n",
    "           .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b85551",
   "metadata": {},
   "source": [
    "You can see here that we've created a new dataframe with a new index. To do it, we used four key operations:\n",
    "\n",
    "1. manipulating rows\n",
    "2. manipulating the index\n",
    "3. manipulating columns\n",
    "4. applying statistics\n",
    "\n",
    "Most operations you could want to do to a single dataframe are covered by these, but there are different options for each of them depending on what you need.\n",
    "\n",
    "Let's now dig a bit more into these operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74396683",
   "metadata": {},
   "source": [
    "### Manipulating Rows\n",
    "\n",
    "Let's create some fake data to show how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=np.reshape(range(36), (6, 6)),\n",
    "    index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "    columns=[\"col\" + str(i) for i in range(6)],\n",
    "    dtype=float,\n",
    ")\n",
    "df[\"col6\"] = [\"apple\", \"orange\", \"pineapple\", \"mango\", \"kiwi\", \"lemon\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1e125",
   "metadata": {},
   "source": [
    "#### Accessing Rows\n",
    "\n",
    "To access a particular row directly, you can use `df.loc['rowname']` or `df.loc[['rowname1', 'rowname1']]` for two different rows.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2faf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"a\", \"b\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18124edd",
   "metadata": {},
   "source": [
    "But you can also access particular rows based on their location in the dataframe using `.iloc`. Remember that Python indices begin from zero, so to retrieve the first row you would use `.iloc[0]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca822472",
   "metadata": {},
   "source": [
    "This works for multiple rows too. Let's grab the first and third rows (in positions 0 and 2) by passing a list of positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381eb34d",
   "metadata": {},
   "source": [
    "There are other ways to access multiple rows that make use of *slicing* but we'll leave that topic for another time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f67ac2",
   "metadata": {},
   "source": [
    "#### Filtering rows with query\n",
    "\n",
    "As with the flights example, we can also filter rows based on a condition using `query`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"col6 == 'kiwi' or col6 == 'pineapple'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000eb292",
   "metadata": {},
   "source": [
    "For numbers, you can also use the greater than and less than signs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"col0 > 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e03f63",
   "metadata": {},
   "source": [
    "In fact, there are lots of options that work with `query`: as well as `>` (greater than), you can use `>=` (greater than or equal to), `<` (less than), `<=` (less than or equal to), `==` (equal to), and `!=` (not equal to). You can also use the commands `and` as well as `or` to combine multiple conditions. Here's an example of `and` from the `flights` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights that departed on January 1\n",
    "flights.query(\"month == 1 and day == 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0af6fc",
   "metadata": {},
   "source": [
    "Note that equality is tested by `==` and *not* by `=`, because the latter is used for assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57a362",
   "metadata": {},
   "source": [
    "#### Re-arranging Rows\n",
    "\n",
    "Again and again, you will want to re-order the rows of your dataframe according to the values in a particular column. **pandas** makes this very easy via the `.sort_values` function. It takes a data frame and a set of column names to sort by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns. For example, the following code sorts by the departure time, which is spread over four columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values([\"year\", \"month\", \"day\", \"dep_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6e9b1",
   "metadata": {},
   "source": [
    "You can use the keyword argument `ascending=False` to re-order by a column or columns in descending order.\n",
    "For example, this code shows the most delayed flights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values(\"dep_delay\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd1856",
   "metadata": {},
   "source": [
    "You can of course combine all of the above row manipulations to solve more complex problems.\n",
    "For example, we could look for the top three destinations of the flights that were most delayed on arrival that left on roughly on time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "       flights.query(\"dep_delay <= 10 and dep_delay >= -10\")\n",
    "       .sort_values(\"arr_delay\", ascending=False)\n",
    "       .iloc[[0, 1, 2]]\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc0b05",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Find all flights that\n",
    "    a. Had an arrival delay of two or more hours\n",
    "    b. Flew to Houston (`\"IAH\"` or `\"HOU\"`)\n",
    "    c. Were operated by United, American, or Delta\n",
    "    d. Departed in summer (July, August, and September)\n",
    "    e. Arrived more than two hours late, but didn't leave late\n",
    "    f. Were delayed by at least an hour, but made up over 30 minutes in flight\n",
    "\n",
    "2.  Sort `flights` to find the flights with longest departure delays.\n",
    "\n",
    "3.  Sort `flights` to find the fastest flights\n",
    "\n",
    "4.  Which flights traveled the farthest?\n",
    "\n",
    "5.  Does it matter what order you used `query()` and `sort_values()` in if you're using both? Why/why not? Think about the results and how much work the functions would have to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4bd0e",
   "metadata": {},
   "source": [
    "### Manipulating Columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d7534ecd9fbc7d385378f8400cf4d6cb9c6175408a574f1c99c5269f08771cc"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
